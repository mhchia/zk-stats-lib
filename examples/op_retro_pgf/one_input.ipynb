{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_amount = 30_000_000\n",
    "min_quorum = 2\n",
    "# min_payout_per_project = 1500\n",
    "min_payout_per_project = 3_000_000\n",
    "\n",
    "# NOTE: votes is a matrix\n",
    "# projects: 0, 1, 2, 3, 4\n",
    "# voter 0:  3, 1, 5, 0, 0\n",
    "# voter 1:  2, 0, 8, 3, 1\n",
    "# voter 2:  1, 1, 2, 4, 0\n",
    "votes = torch.tensor([\n",
    "    [3, 1, 5, 0, 0],\n",
    "    [2, 0, 8, 3, 1],\n",
    "    [1, 1, 2, 4, 0],\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Filter out projects that receives less than `min_quorum` votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_voters=tensor([3, 2, 3, 2, 1])\n",
      "projects_meet_quorum=tensor([ True,  True,  True,  True, False])\n",
      "filtered_votes=tensor([[3, 1, 5, 0, 0],\n",
      "        [2, 0, 8, 3, 0],\n",
      "        [1, 1, 2, 4, 0]])\n"
     ]
    }
   ],
   "source": [
    "project_voters = torch.sum(votes > 0, dim=0)\n",
    "projects_meet_quorum = project_voters >= min_quorum\n",
    "filtered_votes = votes.clone()\n",
    "filtered_votes[:, ~projects_meet_quorum] = 0\n",
    "print(f\"{project_voters=}\")\n",
    "print(f\"{projects_meet_quorum=}\")\n",
    "print(f\"{filtered_votes=}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calculate results based on median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medians=tensor([2., 1., 5., 3., 0.])\n"
     ]
    }
   ],
   "source": [
    "medians = torch.median(filtered_votes.float(), dim=0).values\n",
    "print(f\"{medians=}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Scale project payouts to sum up to 30m OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled payouts: tensor([ 5454545.5000,  2727272.7500, 13636364.0000,  8181818.5000,\n",
      "               0.0000])\n"
     ]
    }
   ],
   "source": [
    "# 3. Scale project payouts to sum up to 30m OP\n",
    "total_medians = torch.sum(medians)\n",
    "proportions_1 = medians.float() / total_medians\n",
    "scaled_payouts_1 = proportions_1 * total_amount\n",
    "print(\"Scaled payouts:\", scaled_payouts_1)\n",
    "sum_after_scaling = int(torch.sum(scaled_payouts_1))\n",
    "assert sum_after_scaling == total_amount"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Filter out all projects which received below `min_payout_per_project` votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "above_payout_threshold=tensor([ True, False,  True,  True, False])\n",
      "Payouts: tensor([ 5454545.5000,        0.0000, 13636364.0000,  8181818.5000,\n",
      "               0.0000])\n"
     ]
    }
   ],
   "source": [
    "above_payout_threshold = scaled_payouts_1 >= min_payout_per_project\n",
    "print(f\"{above_payout_threshold=}\")\n",
    "payouts = scaled_payouts_1.clone()\n",
    "payouts[~above_payout_threshold] = 0\n",
    "print(\"Payouts:\", payouts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Scale project payouts to sum up to 30m OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled payouts: tensor([ 6000000.,        0., 15000000.,  9000000.,        0.])\n"
     ]
    }
   ],
   "source": [
    "total_payout = torch.sum(payouts)\n",
    "proportions_2 = payouts.float() / total_payout\n",
    "scaled_payouts_2 = proportions_2 * total_amount\n",
    "print(\"Scaled payouts:\", scaled_payouts_2)\n",
    "sum_after_scaling = int(torch.sum(scaled_payouts_2))\n",
    "assert sum_after_scaling == total_amount"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try to run it with `ezkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =  torch.Size([1, 3, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_43519/3995020659.py:96: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  return (torch.tensor(1), project_voters)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from zkstats.core import (\n",
    "    gen_settings,\n",
    "    verifier_setup,\n",
    "    prover_setup,\n",
    "    prover_gen_proof,\n",
    "    verifier_verify,\n",
    ")\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "output_dir = f\"{cwd}/out\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "model_onnx_path = f\"{output_dir}/model.onnx\"\n",
    "compiled_model_path = f\"{output_dir}/model.compiled\"\n",
    "pk_path = f\"{output_dir}/model.pk\"\n",
    "vk_path = f\"{output_dir}/model.vk\"\n",
    "proof_path = f\"{output_dir}/model.pf\"\n",
    "settings_path = f\"{output_dir}/settings.json\"\n",
    "srs_path = f\"{output_dir}/kzg.srs\"\n",
    "witness_path = f\"{output_dir}/witness.json\"\n",
    "comb_data_path = f\"{output_dir}/comb_data.json\"\n",
    "\n",
    "# data tensor\n",
    "# NOTE: Can we pass `data_tensor` as the matrix as above?\n",
    "# data = [3.0, 1.0, 5.0, 0.0, 0.0, 2.0, 0.0, 8.0, 3.0, 1.0, 1.0, 1.0, 2.0, 4.0, 0.0]\n",
    "# data_tensor = torch.tensor(data)\n",
    "# data_tensor_1 = torch.reshape(torch.tensor(data),(1, len(data), 1))\n",
    "# comb_data = [data_tensor.tolist()]\n",
    "# with open(comb_data_path, 'w') as f:\n",
    "#     json.dump(dict(input_data = comb_data), f)\n",
    "# data_tensor_array = [data_tensor_1]\n",
    "data =[[3, 1, 5, 0, 0],\n",
    "    [2, 0, 8, 3, 1],\n",
    "    [1, 1, 2, 4, 0],\n",
    "]\n",
    "# here flatten comb_data\n",
    "comb_data = [element for row in data for element in row]\n",
    "with open(comb_data_path, 'w') as f:\n",
    "    json.dump(dict(input_data = [comb_data]), f)\n",
    "\n",
    "data_tensor_array = [torch.reshape(torch.tensor(data), (1, *np.array(data).shape))]\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # # some expression of tolerance to error in the inference\n",
    "        # return filtered_votes\n",
    "        # X is (1, 15, 1)\n",
    "        print(\"x.shape = \", x.shape)\n",
    "        # Y is (1, 15)\n",
    "        # matrix = x.reshape(-1, 5)\n",
    "        # print(\"matrix = \", matrix)\n",
    "        # print(\"matrix.shape = \", matrix.shape)\n",
    "        # print(\"sum X = \", torch.sum(x))\n",
    "        # sum_matrix = torch.sum(matrix, dim=0)\n",
    "        # print(\"sum matrix = \", sum_matrix)\n",
    "\n",
    "        # votes = matrix\n",
    "        # 1.\n",
    "        project_voters = torch.sum((x > 0).double(), dim=1)\n",
    "        # projects_meet_quorum = project_voters >= min_quorum\n",
    "        # filtered_votes = votes.clone()\n",
    "        # filtered_votes[:, ~projects_meet_quorum] = 0\n",
    "        # print(f\"{project_voters=}\")\n",
    "        # print(f\"{projects_meet_quorum=}\")\n",
    "        # print(f\"{filtered_votes=}\")\n",
    "\n",
    "        # # 2.\n",
    "        # medians = torch.mean(filtered_votes.float(), dim=0)\n",
    "        # print(f\"{medians=}\")\n",
    "\n",
    "        # # 3. Scale project payouts to sum up to 30m OP\n",
    "        # total_medians = torch.sum(medians)\n",
    "        # proportions_1 = medians.float() / total_medians\n",
    "        # scaled_payouts_1 = proportions_1 * total_amount\n",
    "        # print(\"Scaled payouts:\", scaled_payouts_1)\n",
    "        # # 4. Filter out all projects which received below `min_payout_per_project` votes\n",
    "        # above_payout_threshold = scaled_payouts_1 >= min_payout_per_project\n",
    "        # print(f\"{above_payout_threshold=}\")\n",
    "        # payouts = scaled_payouts_1.clone()\n",
    "        # payouts[~above_payout_threshold] = 0\n",
    "        # # 5. Scale project payouts to sum up to 30m OP\n",
    "        # total_payout = torch.sum(payouts)\n",
    "        # proportions_2 = payouts.float() / total_payout\n",
    "        # scaled_payouts_2 = proportions_2 * total_amount\n",
    "\n",
    "        # print(\"scaled_payouts_2 = \", scaled_payouts_2)\n",
    "\n",
    "        return (torch.tensor(1), project_voters)\n",
    "\n",
    "        # return (torch.tensor(1), torch.mean(X))\n",
    "\n",
    "\n",
    "# export_onnx\n",
    "circuit = Model()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "circuit.to(device)\n",
    "circuit.eval()\n",
    "input_names = []\n",
    "dynamic_axes = {}\n",
    "\n",
    "data_tensor_tuple = ()\n",
    "for i in range(len(data_tensor_array)):\n",
    "    data_tensor_tuple += (data_tensor_array[i],)\n",
    "    input_index = \"input\"+str(i+1)\n",
    "    input_names.append(input_index)\n",
    "    dynamic_axes[input_index] = {0 : 'batch_size'}\n",
    "    dynamic_axes[\"output\"] = {0 : 'batch_size'}\n",
    "\n",
    "torch.onnx.export(\n",
    "    circuit,               # model being run\n",
    "    data_tensor_tuple,                   # model input (or a tuple for multiple inputs)\n",
    "    model_onnx_path,            # where to save the model (can be a file or file-like object)\n",
    "    export_params=True,        # store the trained parameter weights inside the model file\n",
    "    opset_version=11,          # the ONNX version to export the model to\n",
    "    do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "    input_names = input_names,   # the model's input names\n",
    "    output_names = ['output'], # the model's output names\n",
    "    dynamic_axes=dynamic_axes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Generate & Calibrate Setting ====\n",
      "scale:  default\n",
      "setting:  {\"run_args\":{\"tolerance\":{\"val\":0.0,\"scale\":1.0},\"input_scale\":0,\"param_scale\":7,\"scale_rebase_multiplier\":10,\"lookup_range\":[0,16],\"logrows\":11,\"num_inner_cols\":1,\"variables\":[[\"batch_size\",1]],\"input_visibility\":{\"Hashed\":{\"hash_is_public\":true,\"outlets\":[]}},\"output_visibility\":\"Public\",\"param_visibility\":\"Private\"},\"num_rows\":1312,\"total_assignments\":80,\"total_const_size\":0,\"model_instance_shapes\":[[1],[1,5]],\"model_output_scales\":[0,0],\"model_input_scales\":[0],\"module_sizes\":{\"kzg\":[],\"poseidon\":[1312,[1]],\"elgamal\":[0,[0]]},\"required_lookups\":[{\"GreaterThan\":{\"a\":0.0}}],\"check_mode\":\"UNSAFE\",\"version\":\"5.0.8\",\"num_blinding_factors\":null}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scale = \"default\"\n",
    "mode = \"resources\"\n",
    "gen_settings(comb_data_path, model_onnx_path, scale, mode, settings_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== setting up ezkl ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time setup: 0.32255005836486816 seconds\n"
     ]
    }
   ],
   "source": [
    "verifier_setup(model_onnx_path, compiled_model_path, settings_path, srs_path, vk_path, pk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!@# compiled_model exists? True\n",
      "!@# compiled_model exists? True\n",
      "==== Generating Witness ====\n",
      "witness boolean:  1.0\n",
      "witness result 1 : 3.0\n",
      "witness result 2 : 2.0\n",
      "witness result 3 : 3.0\n",
      "witness result 4 : 2.0\n",
      "witness result 5 : 1.0\n",
      "==== Generating Proof ====\n",
      "proof:  {'instances': [[[4826878671332116395, 4049896233759741249, 7263229682414501492, 1953201551075271732], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [415066004289224689, 11886516471525959549, 3696305541684646538, 3035258219084094862], [6425625360762666998, 7924344314350639699, 14762033076929465436, 2023505479389396574], [415066004289224689, 11886516471525959549, 3696305541684646538, 3035258219084094862], [6425625360762666998, 7924344314350639699, 14762033076929465436, 2023505479389396574], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287]]], 'proof': '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', 'transcript_type': 'EVM'}\n",
      "Time gen prf: 0.29427099227905273 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prover_gen_proof(model_onnx_path, comb_data_path, witness_path, compiled_model_path, settings_path, proof_path, pk_path, srs_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_inputs:  1\n",
      "prf instances:  [[[4826878671332116395, 4049896233759741249, 7263229682414501492, 1953201551075271732], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [415066004289224689, 11886516471525959549, 3696305541684646538, 3035258219084094862], [6425625360762666998, 7924344314350639699, 14762033076929465436, 2023505479389396574], [415066004289224689, 11886516471525959549, 3696305541684646538, 3035258219084094862], [6425625360762666998, 7924344314350639699, 14762033076929465436, 2023505479389396574], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287]]]\n",
      "proof boolean:  1.0\n",
      "proof result 1 : 3.0\n",
      "proof result 2 : 2.0\n",
      "proof result 3 : 3.0\n",
      "proof result 4 : 2.0\n",
      "proof result 5 : 1.0\n",
      "verified\n"
     ]
    }
   ],
   "source": [
    "verifier_verify(proof_path, settings_path, vk_path, srs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
