{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_amount = 30_000_000\n",
    "min_quorum = 2\n",
    "# min_payout_per_project = 1500\n",
    "min_payout_per_project = 3_000_000\n",
    "\n",
    "# NOTE: votes is a matrix\n",
    "# projects: 0, 1, 2, 3, 4\n",
    "# voter 0:  3, 1, 5, 0, 0\n",
    "# voter 1:  2, 0, 8, 3, 1\n",
    "# voter 2:  1, 1, 2, 4, 0\n",
    "votes = torch.tensor([\n",
    "    [3, 1, 5, 0, 0],\n",
    "    [2, 0, 8, 3, 1],\n",
    "    [1, 1, 2, 4, 0],\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Filter out projects that receives less than `min_quorum` votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_voters=tensor([3, 2, 3, 2, 1])\n",
      "projects_meet_quorum=tensor([ True,  True,  True,  True, False])\n",
      "filtered_votes=tensor([[3, 1, 5, 0, 0],\n",
      "        [2, 0, 8, 3, 0],\n",
      "        [1, 1, 2, 4, 0]])\n"
     ]
    }
   ],
   "source": [
    "project_voters = torch.sum(votes > 0, dim=0)\n",
    "projects_meet_quorum = project_voters >= min_quorum\n",
    "filtered_votes = votes.clone()\n",
    "filtered_votes[:, ~projects_meet_quorum] = 0\n",
    "print(f\"{project_voters=}\")\n",
    "print(f\"{projects_meet_quorum=}\")\n",
    "print(f\"{filtered_votes=}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calculate results based on median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medians=tensor([2., 1., 5., 3., 0.])\n"
     ]
    }
   ],
   "source": [
    "medians = torch.median(filtered_votes.float(), dim=0).values\n",
    "print(f\"{medians=}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Scale project payouts to sum up to 30m OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled payouts: tensor([ 5454545.5000,  2727272.7500, 13636364.0000,  8181818.5000,\n",
      "               0.0000])\n"
     ]
    }
   ],
   "source": [
    "# 3. Scale project payouts to sum up to 30m OP\n",
    "total_medians = torch.sum(medians)\n",
    "proportions_1 = medians.float() / total_medians\n",
    "scaled_payouts_1 = proportions_1 * total_amount\n",
    "print(\"Scaled payouts:\", scaled_payouts_1)\n",
    "sum_after_scaling = int(torch.sum(scaled_payouts_1))\n",
    "assert sum_after_scaling == total_amount"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Filter out all projects which received below `min_payout_per_project` votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "above_payout_threshold=tensor([ True, False,  True,  True, False])\n",
      "Payouts: tensor([ 5454545.5000,        0.0000, 13636364.0000,  8181818.5000,\n",
      "               0.0000])\n"
     ]
    }
   ],
   "source": [
    "above_payout_threshold = scaled_payouts_1 >= min_payout_per_project\n",
    "print(f\"{above_payout_threshold=}\")\n",
    "payouts = scaled_payouts_1.clone()\n",
    "payouts[~above_payout_threshold] = 0\n",
    "print(\"Payouts:\", payouts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Scale project payouts to sum up to 30m OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled payouts: tensor([ 6000000.,        0., 15000000.,  9000000.,        0.])\n"
     ]
    }
   ],
   "source": [
    "total_payout = torch.sum(payouts)\n",
    "proportions_2 = payouts.float() / total_payout\n",
    "scaled_payouts_2 = proportions_2 * total_amount\n",
    "print(\"Scaled payouts:\", scaled_payouts_2)\n",
    "sum_after_scaling = int(torch.sum(scaled_payouts_2))\n",
    "assert sum_after_scaling == total_amount"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try to run it with `ezkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 1, 5, 0, 0],\n",
      "        [2, 0, 8, 3, 1],\n",
      "        [1, 1, 2, 4, 0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_43663/3453129250.py:102: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  return (torch.tensor(1), project_voters)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "from zkstats.core import (\n",
    "    gen_settings,\n",
    "    verifier_setup,\n",
    "    prover_setup,\n",
    "    prover_gen_proof,\n",
    "    verifier_verify,\n",
    ")\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "output_dir = f\"{cwd}/out\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "model_onnx_path = f\"{output_dir}/model.onnx\"\n",
    "compiled_model_path = f\"{output_dir}/model.compiled\"\n",
    "pk_path = f\"{output_dir}/model.pk\"\n",
    "vk_path = f\"{output_dir}/model.vk\"\n",
    "proof_path = f\"{output_dir}/model.pf\"\n",
    "settings_path = f\"{output_dir}/settings.json\"\n",
    "srs_path = f\"{output_dir}/kzg.srs\"\n",
    "witness_path = f\"{output_dir}/witness.json\"\n",
    "comb_data_path = f\"{output_dir}/comb_data.json\"\n",
    "\n",
    "# data tensor\n",
    "# NOTE: Can we pass `data_tensor` as the matrix as above?\n",
    "# data = [3.0, 1.0, 5.0, 0.0, 0.0, 2.0, 0.0, 8.0, 3.0, 1.0, 1.0, 1.0, 2.0, 4.0, 0.0]\n",
    "# data_tensor = torch.tensor(data)\n",
    "# data_tensor_1 = torch.reshape(torch.tensor(data),(1, len(data), 1))\n",
    "# comb_data = [data_tensor.tolist()]\n",
    "# with open(comb_data_path, 'w') as f:\n",
    "#     json.dump(dict(input_data = comb_data), f)\n",
    "# data_tensor_array = [data_tensor_1]\n",
    "data =[[3, 1, 5, 0, 0],\n",
    "    [2, 0, 8, 3, 1],\n",
    "    [1, 1, 2, 4, 0],\n",
    "]\n",
    "# here comb_data is redundant, but for clarity\n",
    "comb_data = data\n",
    "with open(comb_data_path, 'w') as f:\n",
    "    json.dump(dict(input_data = comb_data), f)\n",
    "\n",
    "# treat as if we have 3 inputs.\n",
    "data_tensor_array = []\n",
    "for arr in data:\n",
    "    data_tensor_array.append(torch.reshape(torch.tensor(arr), (1, *np.array(arr).shape)))\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "    def forward(self, *args):\n",
    "        # # some expression of tolerance to error in the inference\n",
    "        # return filtered_votes\n",
    "        # X is (1, 15, 1)\n",
    "        # print(\"x.shape = \", x.shape)\n",
    "        # # Y is (1, 15)\n",
    "        # matrix = x.reshape(-1, 5)\n",
    "        # print(\"matrix = \", matrix)\n",
    "        # print(\"matrix.shape = \", matrix.shape)\n",
    "        # print(\"sum X = \", torch.sum(x))\n",
    "        # sum_matrix = torch.sum(matrix, dim=0)\n",
    "        # print(\"sum matrix = \", sum_matrix)\n",
    "\n",
    "        # votes = matrix\n",
    "        # 1.\n",
    "        matrix = torch.cat((args), dim = 0)\n",
    "        print(matrix)\n",
    "        project_voters = torch.sum((matrix > 0).double(), dim=0)\n",
    "        # projects_meet_quorum = project_voters >= min_quorum\n",
    "        # filtered_votes = votes.clone()\n",
    "        # filtered_votes[:, ~projects_meet_quorum] = 0\n",
    "        # print(f\"{project_voters=}\")\n",
    "        # print(f\"{projects_meet_quorum=}\")\n",
    "        # print(f\"{filtered_votes=}\")\n",
    "\n",
    "        # # 2.\n",
    "        # medians = torch.mean(filtered_votes.float(), dim=0)\n",
    "        # print(f\"{medians=}\")\n",
    "\n",
    "        # # 3. Scale project payouts to sum up to 30m OP\n",
    "        # total_medians = torch.sum(medians)\n",
    "        # proportions_1 = medians.float() / total_medians\n",
    "        # scaled_payouts_1 = proportions_1 * total_amount\n",
    "        # print(\"Scaled payouts:\", scaled_payouts_1)\n",
    "        # # 4. Filter out all projects which received below `min_payout_per_project` votes\n",
    "        # above_payout_threshold = scaled_payouts_1 >= min_payout_per_project\n",
    "        # print(f\"{above_payout_threshold=}\")\n",
    "        # payouts = scaled_payouts_1.clone()\n",
    "        # payouts[~above_payout_threshold] = 0\n",
    "        # # 5. Scale project payouts to sum up to 30m OP\n",
    "        # total_payout = torch.sum(payouts)\n",
    "        # proportions_2 = payouts.float() / total_payout\n",
    "        # scaled_payouts_2 = proportions_2 * total_amount\n",
    "\n",
    "        # print(\"scaled_payouts_2 = \", scaled_payouts_2)\n",
    "\n",
    "        return (torch.tensor(1), project_voters)\n",
    "\n",
    "        # return (torch.tensor(1), torch.mean(X))\n",
    "\n",
    "\n",
    "# export_onnx\n",
    "circuit = Model()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "circuit.to(device)\n",
    "circuit.eval()\n",
    "input_names = []\n",
    "dynamic_axes = {}\n",
    "\n",
    "data_tensor_tuple = ()\n",
    "for i in range(len(data_tensor_array)):\n",
    "    data_tensor_tuple += (data_tensor_array[i],)\n",
    "    input_index = \"input\"+str(i+1)\n",
    "    input_names.append(input_index)\n",
    "    dynamic_axes[input_index] = {0 : 'batch_size'}\n",
    "    dynamic_axes[\"output\"] = {0 : 'batch_size'}\n",
    "\n",
    "torch.onnx.export(\n",
    "    circuit,               # model being run\n",
    "    data_tensor_tuple,                   # model input (or a tuple for multiple inputs)\n",
    "    model_onnx_path,            # where to save the model (can be a file or file-like object)\n",
    "    export_params=True,        # store the trained parameter weights inside the model file\n",
    "    opset_version=11,          # the ONNX version to export the model to\n",
    "    do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "    input_names = input_names,   # the model's input names\n",
    "    output_names = ['output'], # the model's output names\n",
    "    dynamic_axes=dynamic_axes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Generate & Calibrate Setting ====\n",
      "scale:  default\n",
      "setting:  {\"run_args\":{\"tolerance\":{\"val\":0.0,\"scale\":1.0},\"input_scale\":0,\"param_scale\":7,\"scale_rebase_multiplier\":10,\"lookup_range\":[0,16],\"logrows\":12,\"num_inner_cols\":1,\"variables\":[[\"batch_size\",1]],\"input_visibility\":{\"Hashed\":{\"hash_is_public\":true,\"outlets\":[]}},\"output_visibility\":\"Public\",\"param_visibility\":\"Private\"},\"num_rows\":3936,\"total_assignments\":80,\"total_const_size\":0,\"model_instance_shapes\":[[1],[5]],\"model_output_scales\":[0,0],\"model_input_scales\":[0,0,0],\"module_sizes\":{\"kzg\":[],\"poseidon\":[3936,[3]],\"elgamal\":[0,[0]]},\"required_lookups\":[{\"GreaterThan\":{\"a\":0.0}}],\"check_mode\":\"UNSAFE\",\"version\":\"5.0.8\",\"num_blinding_factors\":null}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scale = \"default\"\n",
    "mode = \"resources\"\n",
    "gen_settings(comb_data_path, model_onnx_path, scale, mode, settings_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== setting up ezkl ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time setup: 0.44379091262817383 seconds\n"
     ]
    }
   ],
   "source": [
    "verifier_setup(model_onnx_path, compiled_model_path, settings_path, srs_path, vk_path, pk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!@# compiled_model exists? True\n",
      "!@# compiled_model exists? True\n",
      "==== Generating Witness ====\n",
      "witness boolean:  1.0\n",
      "witness result 1 : 3.0\n",
      "witness result 2 : 2.0\n",
      "witness result 3 : 3.0\n",
      "witness result 4 : 2.0\n",
      "witness result 5 : 1.0\n",
      "==== Generating Proof ====\n",
      "proof:  {'instances': [[[9296357989369544422, 806886128735292534, 17227576304493195516, 1051098193777516077], [3648264528554272805, 9943096230673625608, 14654808276757294795, 2213601918623149515], [17068183099411130464, 16329882580612051180, 1425198730632413878, 1859139276191188365], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [415066004289224689, 11886516471525959549, 3696305541684646538, 3035258219084094862], [6425625360762666998, 7924344314350639699, 14762033076929465436, 2023505479389396574], [415066004289224689, 11886516471525959549, 3696305541684646538, 3035258219084094862], [6425625360762666998, 7924344314350639699, 14762033076929465436, 2023505479389396574], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287]]], 'proof': '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', 'transcript_type': 'EVM'}\n",
      "Time gen prf: 0.6097431182861328 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prover_gen_proof(model_onnx_path, comb_data_path, witness_path, compiled_model_path, settings_path, proof_path, pk_path, srs_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_inputs:  3\n",
      "prf instances:  [[[9296357989369544422, 806886128735292534, 17227576304493195516, 1051098193777516077], [3648264528554272805, 9943096230673625608, 14654808276757294795, 2213601918623149515], [17068183099411130464, 16329882580612051180, 1425198730632413878, 1859139276191188365], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [415066004289224689, 11886516471525959549, 3696305541684646538, 3035258219084094862], [6425625360762666998, 7924344314350639699, 14762033076929465436, 2023505479389396574], [415066004289224689, 11886516471525959549, 3696305541684646538, 3035258219084094862], [6425625360762666998, 7924344314350639699, 14762033076929465436, 2023505479389396574], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287]]]\n",
      "proof boolean:  1.0\n",
      "proof result 1 : 3.0\n",
      "proof result 2 : 2.0\n",
      "proof result 3 : 3.0\n",
      "proof result 4 : 2.0\n",
      "proof result 5 : 1.0\n",
      "verified\n"
     ]
    }
   ],
   "source": [
    "verifier_verify(proof_path, settings_path, vk_path, srs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
